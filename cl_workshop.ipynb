{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import Accuracy\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes=10,\n",
    "        input_channels=1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self._conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self._lf1 = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=9216,\n",
    "                out_features=128,\n",
    "            ),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(),\n",
    "        )\n",
    "        self._lf2 = nn.Linear(\n",
    "            in_features=128,\n",
    "            out_features=n_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self._conv1(x)\n",
    "        x = self._conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self._lf1(x)\n",
    "        x = self._lf2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './tmp/'\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 1000\n",
    "SEED = 1\n",
    "torch.manual_seed(1)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=datasets.MNIST(\n",
    "        root=DATA_PATH,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=datasets.MNIST(\n",
    "        root=DATA_PATH,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_loader: DataLoader, epoch: int, optimizer: torch.optim.Optimizer,) -> None:\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 250 == 0:\n",
    "      print(\n",
    "        f'Train Epoch: {epoch}, [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}'\n",
    "      )\n",
    "\n",
    "    # torch.save(model.state_dict(), './results/model.pth')\n",
    "    # torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "\n",
    "def test(model: nn.Module, test_loader: DataLoader,) -> None:\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "\n",
    "  preds = torch.tensor([]).to(DEVICE)\n",
    "  expected = torch.tensor([]).to(DEVICE)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "      output = model(data)\n",
    "      test_loss += F.nll_loss(output, target)\n",
    "\n",
    "      pred = output.max(1)[1]\n",
    "      preds = torch.cat((preds, pred))\n",
    "      expected = torch.cat((expected, target))\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  acc = Accuracy(task=\"multiclass\", num_classes=10).to(DEVICE)\n",
    "\n",
    "  print(f'Test Accuracy: {acc(preds, expected).item():.2f}')\n",
    "  print(f'Test set: Avg. loss: {test_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train(epoch=epoch, model=model, train_loader=train_loader, optimizer=optimizer,)\n",
    "    test(model=model, test_loader=test_loader,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.permute(x, (0, 2, 1)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader2 = DataLoader(\n",
    "    dataset=datasets.MNIST(\n",
    "        root=DATA_PATH,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform2,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader2 = DataLoader(\n",
    "    dataset=datasets.MNIST(\n",
    "        root=DATA_PATH,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform2,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model=model, test_loader=test_loader2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train(epoch=epoch, model=model, train_loader=train_loader2, optimizer=optimizer,)\n",
    "    test(model=model, test_loader=test_loader2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing on the first task:\")\n",
    "test(model=model, test_loader=test_loader,)\n",
    "\n",
    "print(\"Testing on the second task:\")\n",
    "test(model=model, test_loader=test_loader2,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.supervised import Naive\n",
    "from avalanche.benchmarks.classic import PermutedMNIST\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics\n",
    "from avalanche.logging import InteractiveLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_mnist = PermutedMNIST(n_experiences=5, seed=SEED)\n",
    "train_stream = permuted_mnist.train_stream\n",
    "test_stream = permuted_mnist.test_stream\n",
    "\n",
    "cl_strategy = Naive(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_strategy.train(train_stream)\n",
    "results = cl_strategy.eval(test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.supervised import EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = EWC(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    ewc_lambda=0.4,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_strategy.train(train_stream)\n",
    "results = cl_strategy.eval(test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewc_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.supervised import GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = GEM(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    patterns_per_exp=200,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_strategy.train(train_stream)\n",
    "results = cl_strategy.eval(test_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=pd.DataFrame({'Naive': naive_results, 'EWC': ewc_results, 'GEM': gem_results}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic import SplitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_mnist = SplitMNIST(n_experiences=2, seed=SEED, fixed_class_order= [0, 2, 4, 6, 8, 1, 3, 5, 7, 9])\n",
    "train_stream = permuted_mnist.train_stream\n",
    "test_stream = permuted_mnist.test_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = Naive(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "for stream in train_stream:\n",
    "    print(f'Classes in this experience: {stream.classes_in_this_experience}')\n",
    "    cl_strategy.train(stream)\n",
    "results = cl_strategy.eval(test_stream)\n",
    "\n",
    "naive_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = EWC(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    ewc_lambda=0.2,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "for stream in train_stream:\n",
    "    print(f'Classes in this experience: {stream.classes_in_this_experience}')\n",
    "    cl_strategy.train(stream)\n",
    "results = cl_strategy.eval(test_stream)\n",
    "\n",
    "ewc_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = GEM(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    patterns_per_exp=200,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "for stream in train_stream:\n",
    "    print(f'Classes in this experience: {stream.classes_in_this_experience}')\n",
    "    cl_strategy.train(stream)\n",
    "results = cl_strategy.eval(test_stream)\n",
    "\n",
    "gem_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=pd.DataFrame({'Naive': naive_results, 'EWC': ewc_results, 'GEM': gem_results}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.generators import nc_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(28, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train = datasets.CIFAR100(root='./tmp', transform=train_transform, train=True, download=True,)\n",
    "cifar_test = datasets.CIFAR100(root='./tmp', transform=test_transform, train=False, download=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = nc_benchmark(\n",
    "    train_dataset=cifar_train,\n",
    "    test_dataset=cifar_test,\n",
    "    n_experiences=5,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    task_labels=False,\n",
    ")\n",
    "\n",
    "cifar_train_stream = scenario.train_stream\n",
    "cifar_test_stream = scenario.test_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_classes=100, input_channels=3,).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = Naive(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "cl_strategy.train(cifar_train_stream)\n",
    "results = cl_strategy.eval(cifar_test_stream)\n",
    "\n",
    "naive_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_classes=100, input_channels=3,).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = EWC(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    ewc_lambda=0.2,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "cl_strategy.train(cifar_train_stream)\n",
    "results = cl_strategy.eval(cifar_test_stream)\n",
    "\n",
    "ewc_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_classes=100, input_channels=3,).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate,)\n",
    "\n",
    "cl_strategy = GEM(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=F.nll_loss,\n",
    "    train_mb_size=BATCH_SIZE_TRAIN,\n",
    "    train_epochs=n_epochs,\n",
    "    eval_mb_size=BATCH_SIZE_TEST,\n",
    "    device=DEVICE,\n",
    "    patterns_per_exp=200,\n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(stream=True),\n",
    "        loggers=[InteractiveLogger()],\n",
    "        strict_checks=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "cl_strategy.train(cifar_train_stream)\n",
    "results = cl_strategy.eval(cifar_test_stream)\n",
    "\n",
    "gem_results = [results[key] for key in results.keys() if 'Exp' in key]\n",
    "for key in results.keys():\n",
    "    print(f'{key}: {results[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=pd.DataFrame({'Naive': naive_results, 'EWC': ewc_results, 'GEM': gem_results}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
